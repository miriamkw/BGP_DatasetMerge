{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data Diagnostics\n",
    "\n",
    "This notebook is to check the data quality for each subject, and to find out if some subjects have data that looks strange and we should look more into. \n",
    "\n",
    "What we are checking here:\n",
    "- Min / Max / Mean values of relevant features (CGM and heartrate), compared to predefined expectations and thresholds\n",
    "- Ratios between basal / bolus / carbs to check for unreasonable data\n",
    "- Verify that time intervals are correct\n",
    "- Feature sparsity in train / test data for each subject after imputation\n",
    "\n",
    "Results storage and visualization:\n",
    "- Saving a dataframe with results\n",
    "- Plot results in color coded tables "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "80d7ef5913f237d8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "238578fc2bff6230"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-04T21:20:27.864333Z",
     "start_time": "2024-12-04T21:20:27.626777Z"
    }
   },
   "id": "698205be2b05f1e7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "85405ff7ffbf3df9"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "folder = 'processed_data'\n",
    "file_name = 'tidepool_dataset.csv'\n",
    "df = pd.read_csv(os.path.join('..', folder, file_name), index_col='date', parse_dates=['date'], low_memory=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-04T21:21:56.428628Z",
     "start_time": "2024-12-04T21:20:27.876478Z"
    }
   },
   "id": "653654319fc1272d"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject HCL150-094f81301c6b8e8936d557200006d4430de32971d7ebb8ea41d72a243640c84b has invalid intervals found: date\n",
      "2018-03-26 01:10:00+00:00                   NaT\n",
      "2018-03-26 00:10:00+00:00   -567 days +00:10:00\n",
      "2019-10-14 00:05:00+00:00     566 days 23:00:00\n",
      "Name: date, dtype: timedelta64[ns]\n",
      "Subject HCL150-1be3cb72496c6373f5df107af201c13773e46dc9db7cf93161ab81d7ee62e7a4 has invalid intervals found: date\n",
      "2019-02-12 02:15:00+00:00                   NaT\n",
      "2019-02-12 01:05:00+00:00   -244 days +01:05:00\n",
      "2019-02-12 00:05:00+00:00     -1 days +21:55:00\n",
      "Name: date, dtype: timedelta64[ns]\n",
      "Subject HCL150-1eb65ac8c57a13526a40cc735d7f02c618d36f8d3a8af7b801d6c28ddaf28b36 has invalid intervals found: date\n",
      "2019-10-14 00:40:00+00:00                  NaT\n",
      "2019-10-14 00:05:00+00:00   -30 days +00:05:00\n",
      "Name: date, dtype: timedelta64[ns]\n",
      "Subject HCL150-40b9676cffac53ccb404b57b8009590380e4479360773f84151a1289e45d5825 has invalid intervals found: date\n",
      "2019-06-26 03:20:00+00:00                   NaT\n",
      "2019-06-26 02:25:00+00:00   -101 days +02:25:00\n",
      "2019-06-26 02:05:00+00:00     -1 days +22:50:00\n",
      "2019-10-05 00:05:00+00:00     100 days 21:45:00\n",
      "Name: date, dtype: timedelta64[ns]\n",
      "Subject HCL150-4493e76cf532714c64b9b0ca7ff233a3e864b2589c08a69783e101d40af1d596 has invalid intervals found: date\n",
      "2019-05-31 05:05:00+00:00                   NaT\n",
      "2019-05-31 00:05:00+00:00   -135 days +00:05:00\n",
      "Name: date, dtype: timedelta64[ns]\n",
      "Subject HCL150-4846ac342f7e011e5515517c0a805f97759aa01205ca7ab0a053bb47159f7964 has invalid intervals found: date\n",
      "2019-03-07 00:55:00+00:00                   NaT\n",
      "2019-03-07 00:05:00+00:00   -221 days +00:05:00\n",
      "Name: date, dtype: timedelta64[ns]\n",
      "Subject HCL150-94c1e44276a8a1b66086e46a47812626028ac534996d60782fe3745ae3caf456 has invalid intervals found: date\n",
      "2018-10-05 04:20:00+00:00                   NaT\n",
      "2018-10-05 00:15:00+00:00   -374 days +00:15:00\n",
      "2019-10-14 00:05:00+00:00     373 days 19:50:00\n",
      "Name: date, dtype: timedelta64[ns]\n",
      "Subject HCL150-ac12ffc5a1a6702a0e8308557ba7aa3aa67cc6d6a3c4b3c2322fb1f47ff7989f has invalid intervals found: date\n",
      "2018-07-19 01:50:00+00:00                   NaT\n",
      "2018-07-19 01:35:00+00:00   -280 days +01:35:00\n",
      "2018-07-19 00:15:00+00:00     -1 days +22:30:00\n",
      "Name: date, dtype: timedelta64[ns]\n",
      "Subject HCL150-ad5e634276063cc617a900e7f90fbbbe7d16aaf5b6c11dccf9d8de94c2bcb217 has invalid intervals found: date\n",
      "2018-09-05 00:40:00+00:00                   NaT\n",
      "2018-09-05 00:10:00+00:00   -232 days +00:10:00\n",
      "2018-09-05 00:05:00+00:00     -1 days +23:30:00\n",
      "2019-04-25 00:05:00+00:00     232 days 00:00:00\n",
      "Name: date, dtype: timedelta64[ns]\n",
      "Subject HCL150-ce8e92832ff289e5f816c9ea27d5377e7c7c253a4699da86c5a01ec5212e85c1 has invalid intervals found: date\n",
      "2018-11-10 05:05:00+00:00                   NaT\n",
      "2018-11-10 03:30:00+00:00   -338 days +03:30:00\n",
      "2019-10-14 00:05:00+00:00     337 days 19:05:00\n",
      "Name: date, dtype: timedelta64[ns]\n",
      "Subject HCL150-d8361e87da64cb47bf498c13cc9f1db62be48f6a18845d01e66e137bce8551cf has invalid intervals found: date\n",
      "2019-07-01 03:35:00+00:00                   NaT\n",
      "2019-07-01 01:25:00+00:00   -105 days +01:25:00\n",
      "2019-07-01 00:30:00+00:00     -1 days +21:00:00\n",
      "Name: date, dtype: timedelta64[ns]\n",
      "Subject HCL150-db4aab25d6d3ba9abcc70660cf0447ee1f410fc8a0fbe4cc06d40b4b37dbb28a has invalid intervals found: date\n",
      "2019-05-26 04:30:00+00:00                   NaT\n",
      "2019-05-26 04:05:00+00:00   -141 days +04:05:00\n",
      "Name: date, dtype: timedelta64[ns]\n",
      "Subject HCL150-dbc3d6a255738601c160646246e3a02014cc3524cc838ce120cc45e894016792 has invalid intervals found: date\n",
      "2019-10-14 01:50:00+00:00                  NaT\n",
      "2019-10-14 00:10:00+00:00   -30 days +00:15:00\n",
      "Name: date, dtype: timedelta64[ns]\n",
      "Subject HCL150-dee1fe0420641994d9af91cf2a59aeeed7f6de7a18d09f557a431a8302949418 has invalid intervals found: date\n",
      "2019-05-27 02:15:00+00:00                   NaT\n",
      "2019-05-27 01:05:00+00:00   -138 days +01:05:00\n",
      "Name: date, dtype: timedelta64[ns]\n",
      "Subject HCL150-e18cd939a52012e184c9aea5123ce421b152087e6f85d2fbbc86d25d578194fc has invalid intervals found: date\n",
      "2018-09-09 03:15:00+00:00                   NaT\n",
      "2018-09-09 00:25:00+00:00   -400 days +00:25:00\n",
      "2018-09-09 00:05:00+00:00     -1 days +20:55:00\n",
      "2019-10-14 00:05:00+00:00     399 days 23:45:00\n",
      "Name: date, dtype: timedelta64[ns]\n",
      "Subject PA50-152a46fb81b87f7220db4c75f2437d48e5fcb441300cb8ba95f90aa8067d4c91 has invalid intervals found: date\n",
      "2019-01-26 04:35:00+00:00                   NaT\n",
      "2019-01-26 01:25:00+00:00   -247 days +01:25:00\n",
      "2019-09-30 00:05:00+00:00     246 days 19:35:00\n",
      "Name: date, dtype: timedelta64[ns]\n",
      "Subject PA50-6e7d9fe9e6ad5a6ccd653953ddd0dba034c0ae126a5ba60eaaac6e4c43f3a3d3 has invalid intervals found: date\n",
      "2019-10-13 02:25:00+00:00                  NaT\n",
      "2019-10-13 02:10:00+00:00   -30 days +02:10:00\n",
      "Name: date, dtype: timedelta64[ns]\n",
      "Subject PA50-9ef65690d0812dea9f64ed6948b43321b5fc5ad73877d30fd2c1f84eeec2b293 has invalid intervals found: date\n",
      "2018-10-26 03:00:00+00:00                   NaT\n",
      "2018-10-26 01:05:00+00:00   -215 days +01:05:00\n",
      "2019-05-29 00:05:00+00:00     214 days 21:10:00\n",
      "Name: date, dtype: timedelta64[ns]\n",
      "Subject PA50-b7029b5a94b012a4a2331b59284de95d39ef7e5f80a9e3d47828729c5fb528cd has invalid intervals found: date\n",
      "2019-10-14 02:20:00+00:00                  NaT\n",
      "2019-10-14 01:05:00+00:00   -30 days +01:05:00\n",
      "2019-11-13 00:05:00+00:00     29 days 21:50:00\n",
      "Name: date, dtype: timedelta64[ns]\n",
      "Subject PA50-dd24d2573f31d10e9b3e9167fb90edf116ce987c4124afd964b1750713a4f6cd has invalid intervals found: date\n",
      "2018-08-29 02:40:00+00:00                   NaT\n",
      "2018-08-29 00:15:00+00:00   -122 days +00:15:00\n",
      "2018-08-29 00:10:00+00:00     -1 days +21:35:00\n",
      "2018-12-29 00:05:00+00:00     121 days 23:55:00\n",
      "Name: date, dtype: timedelta64[ns]\n",
      "Subject SAP100-07f024f9b2df04a3556a231aca535df04709564d261534d4815c3cb1ba33a5ef has invalid intervals found: date\n",
      "2017-05-28 05:25:00+00:00                   NaT\n",
      "2017-05-28 01:40:00+00:00   -692 days +01:40:00\n",
      "2019-04-20 00:05:00+00:00     691 days 18:45:00\n",
      "Name: date, dtype: timedelta64[ns]\n",
      "Subject SAP100-160102103a951851ef4f652ec2b2051b325148d5ca0736f6a17c5ad927b2952d has invalid intervals found: date\n",
      "2018-09-29 08:55:00+00:00                  NaT\n",
      "2018-09-29 06:10:00+00:00   -90 days +06:10:00\n",
      "2018-09-29 01:05:00+00:00    -1 days +16:15:00\n",
      "2018-12-28 00:05:00+00:00     89 days 18:00:00\n",
      "Name: date, dtype: timedelta64[ns]\n",
      "Subject SAP100-8103ebf9541dd56bd0fdd7517a600b6f169bd6de70d1ca8697713632c9a78103 has invalid intervals found: date\n",
      "2017-09-24 04:00:00+00:00                   NaT\n",
      "2017-09-24 01:05:00+00:00   -347 days +01:05:00\n",
      "2018-09-06 00:05:00+00:00     346 days 20:10:00\n",
      "Name: date, dtype: timedelta64[ns]\n",
      "Subject SAP100-83ce9ebcbeb53a3dfc0899d3bad758902b7f29453a6baf7ebdd46bed2442a8cc has invalid intervals found: date\n",
      "2018-11-03 01:50:00+00:00                   NaT\n",
      "2018-11-03 00:20:00+00:00   -153 days +00:20:00\n",
      "2019-04-05 00:05:00+00:00     152 days 22:20:00\n",
      "Name: date, dtype: timedelta64[ns]\n",
      "Subject SAP100-9518e98aecadf17e9a11b40bcac02f5143f442c919bb009c087610edce6b9582 has invalid intervals found: date\n",
      "2017-12-23 03:05:00+00:00                   NaT\n",
      "2017-12-23 02:35:00+00:00   -439 days +02:35:00\n",
      "2019-03-07 00:05:00+00:00     438 days 21:05:00\n",
      "Name: date, dtype: timedelta64[ns]\n",
      "Subject SAP100-99399ae8b4a495f28f8f82fe55b548563716fbf31e59286adf63e357b70fc837 has invalid intervals found: date\n",
      "2017-03-27 00:40:00+00:00                   NaT\n",
      "2017-03-27 00:35:00+00:00   -451 days +00:35:00\n",
      "2018-06-21 00:05:00+00:00     450 days 23:30:00\n",
      "Name: date, dtype: timedelta64[ns]\n",
      "Subject SAP100-abfc04caa79b02e8b7f51c16a864ac8c0102e2d8c786b1dab674425140dabb86 has invalid intervals found: date\n",
      "2017-01-02 00:10:00+00:00                   NaT\n",
      "2017-01-02 00:05:00+00:00   -361 days +00:05:00\n",
      "2017-12-29 00:05:00+00:00     361 days 00:00:00\n",
      "Name: date, dtype: timedelta64[ns]\n",
      "Subject SAP100-d5894931a34262b5d46bf9c82d98cd1ccadc9392c3f0d0c82322b14ceadb44ba has invalid intervals found: date\n",
      "2017-12-02 01:55:00+00:00                   NaT\n",
      "2017-12-02 01:05:00+00:00   -641 days +01:35:00\n",
      "2019-09-03 23:35:00+00:00     640 days 21:45:00\n",
      "Name: date, dtype: timedelta64[ns]\n",
      "Subject SAP100-d5894931a34262b5d46bf9c82d98cd1ccadc9392c3f0d0c82322b14ceadb44ba has invalid intervals found: date\n",
      "2019-09-04 00:25:00+00:00                  NaT\n",
      "2019-09-04 00:05:00+00:00   -90 days +00:05:00\n",
      "2019-12-03 00:05:00+00:00     89 days 23:45:00\n",
      "Name: date, dtype: timedelta64[ns]\n",
      "Subject SAP100-e350eda6da44c7cecca73bfac0d5c7bc74a2ab28602dd57eb58076571a394eda has invalid intervals found: date\n",
      "2015-05-27 03:55:00+00:00                   NaT\n",
      "2015-05-27 00:50:00+00:00   -661 days +00:50:00\n",
      "2017-03-18 00:05:00+00:00     660 days 20:15:00\n",
      "Name: date, dtype: timedelta64[ns]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Trim data in the beginning and end for each subject\n",
    "# TODO: Create a dataframe where each row is an id, and each column is a feature sparsity\n",
    "train_data = []\n",
    "test_data = []\n",
    "\n",
    "for subject_id, subset_df in df.groupby('id'): \n",
    "    def get_data_from_trimmed_data(df_subset, is_test=True):        \n",
    "        # Validating time intervals\n",
    "        time_diffs = df_subset.index.to_series().diff()\n",
    "        expected_interval = pd.Timedelta(minutes=5)\n",
    "        valid_intervals = (time_diffs[1:] == expected_interval).all()\n",
    "        if not valid_intervals:\n",
    "            invalid_intervals = time_diffs[time_diffs != expected_interval]\n",
    "            print(f\"Subject {subject_id} has invalid intervals found:\", invalid_intervals)\n",
    "        \n",
    "        cgm_col = 'CGM_smoothed' if 'CGM_smoothed' in df_subset.columns else 'CGM'\n",
    "        \n",
    "        # Trim data from nan values in the beginning and end\n",
    "        first_valid_index = df_subset[cgm_col].first_valid_index()\n",
    "        last_valid_index = df_subset[cgm_col].last_valid_index()\n",
    "        if first_valid_index is not None and last_valid_index is not None:\n",
    "            trimmed_subject_data = df_subset.loc[first_valid_index:last_valid_index]\n",
    "        else:\n",
    "            print(f'Subject {subject_id} for is_test {is_test} does not have valid data! DF is probably empty.')\n",
    "            return        \n",
    "        def safe_round(val):\n",
    "            if pd.isna(val):  # Check if the value is NaN\n",
    "                return val  # Return NaN as is\n",
    "            else:\n",
    "                return round(val)  # Round the value if it's not NaN\n",
    "        daily_bolus = safe_round(trimmed_subject_data['bolus'].mean() * 12*24)\n",
    "        daily_basal = safe_round(trimmed_subject_data['basal'].mean()/12 * 12*24)\n",
    "        daily_carbs = safe_round(trimmed_subject_data['carbs'].mean() * 12*24)\n",
    "        basal_ratio = safe_round(daily_basal / (daily_bolus + daily_basal) * 100)\n",
    "        \n",
    "        subject_summary = {\n",
    "            'subject_id': subject_id,\n",
    "            'mean_CGM': safe_round(trimmed_subject_data[cgm_col].mean()),\n",
    "            'min_CGM': safe_round(trimmed_subject_data[cgm_col].min()),\n",
    "            'max_CGM': safe_round(trimmed_subject_data[cgm_col].max()),\n",
    "            'daily_basal_ratio': basal_ratio,\n",
    "            'daily_bolus_ratio': 100 - basal_ratio,\n",
    "            'daily_carbs_ratio': np.nan if daily_carbs == 0 else safe_round(daily_bolus / daily_carbs * 100),\n",
    "            #'is_test': is_test,\n",
    "        }\n",
    "        if 'heartrate' in trimmed_subject_data.columns:\n",
    "            subject_summary['mean_heartrate']: safe_round(trimmed_subject_data['heartrate'].mean())\n",
    "            subject_summary['min_heartrate']: safe_round(trimmed_subject_data['heartrate'].min())\n",
    "            subject_summary['max_heartrate']: safe_round(trimmed_subject_data['heartrate'].max())\n",
    "        \n",
    "        # Add sparsity of each feature\n",
    "        for col in trimmed_subject_data.columns:\n",
    "            if not col in ['id', 'is_test']:\n",
    "                nan_percentage = round(trimmed_subject_data[col].isna().mean() * 100, 1)\n",
    "                subject_summary[col] = nan_percentage\n",
    "        return subject_summary\n",
    "    \n",
    "    train_data.append(get_data_from_trimmed_data(subset_df[subset_df['is_test'] == False], False))\n",
    "    test_data.append(get_data_from_trimmed_data(subset_df[subset_df['is_test'] == True], True))    \n",
    "    \n",
    "train_summary_df = pd.DataFrame(train_data)\n",
    "test_summary_df = pd.DataFrame(test_data)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-04T21:29:04.906800Z",
     "start_time": "2024-12-04T21:28:58.439657Z"
    }
   },
   "id": "2fa2d797000e940"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_summary_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-04T21:22:00.591848Z"
    }
   },
   "id": "6e8d5dee7af5a652"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create a Styled CSV for Feature Sparsity"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b7efb6d5bee54484"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def style_feature_sparsity(df_features):\n",
    "    exclude_substrings = ['id', 'is_test', 'daily', 'mean', 'min', 'max']\n",
    "    features = [col for col in train_summary_df.columns if not any(substring in col for substring in exclude_substrings)]\n",
    "    \n",
    "    # Function to convert RGB to Hex\n",
    "    def rgb_to_hex(r, g, b):\n",
    "        \"\"\"Convert RGB to hex color.\"\"\"\n",
    "        return f'#{int(r):02x}{int(g):02x}{int(b):02x}'\n",
    "    \n",
    "    # Define styling function for color scale\n",
    "    def highlight_severity(val):\n",
    "        if pd.isna(val):  # Check if the value is NaN\n",
    "            return 'background-color: white'  # White for NaN\n",
    "        if val < 30:\n",
    "            red, green, blue = 0, 255, 0  # Green for values less than 30\n",
    "        elif val < 70:\n",
    "            red, green, blue = 255, 255, 0  # Yellow for values less than 70\n",
    "        else:\n",
    "            red, green, blue = 255, 0, 0  # Red for values 70 and above\n",
    "        hex_color = rgb_to_hex(red, green, blue)\n",
    "        return f'background-color: {hex_color}'\n",
    "    \n",
    "    df_features = df_features.style.applymap(highlight_severity, subset=features)\n",
    "    return df_features"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-04T21:29:41.193804Z",
     "start_time": "2024-12-04T21:29:41.188789Z"
    }
   },
   "id": "3c858d60b9dff8f1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Check if CGM and Heartrate Values are Reasonable"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d4f2c6fae1d93bbc"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def rgb_to_hex(r, g, b):\n",
    "    \"\"\"Convert RGB to hex color.\"\"\"\n",
    "    return f'#{int(r):02x}{int(g):02x}{int(b):02x}'\n",
    "\n",
    "def highlight_range_severity(val, range_min, range_max):\n",
    "    if pd.isna(val):\n",
    "        return 'background-color: white'\n",
    "    if range_min <= val <= range_max:\n",
    "        red = 0  # No red component\n",
    "        green = 255  # Full green\n",
    "        blue = 0  # No blue component\n",
    "    else:\n",
    "        red = 255  # Full red\n",
    "        green = 0  # No green component\n",
    "        blue = 0  # No blue component\n",
    "    hex_color = rgb_to_hex(red, green, blue)\n",
    "    return f'background-color: {hex_color}'\n",
    "\n",
    "def style_cgm_and_heartrate(df_features):\n",
    "    df_features = df_features.applymap(lambda val: highlight_range_severity(val, 70, 220), subset=['mean_CGM'])\n",
    "    df_features = df_features.applymap(lambda val: highlight_range_severity(val, 10, 100), subset=['min_CGM'])\n",
    "    df_features = df_features.applymap(lambda val: highlight_range_severity(val, 200, 750), subset=['max_CGM'])\n",
    "    \n",
    "    if 'mean_heartrate' in df_features.columns:\n",
    "        df_features = df_features.applymap(lambda val: highlight_range_severity(val, 30, 100), subset=['mean_heartrate'])\n",
    "        df_features = df_features.applymap(lambda val: highlight_range_severity(val, 30, 100), subset=['min_heartrate'])\n",
    "        df_features = df_features.applymap(lambda val: highlight_range_severity(val, 80, 250), subset=['max_heartrate'])\n",
    "    \n",
    "    return df_features"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-04T21:30:10.910897Z",
     "start_time": "2024-12-04T21:30:10.903689Z"
    }
   },
   "id": "6462a0ab0d9834ac"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-04T21:29:41.801071Z",
     "start_time": "2024-12-04T21:29:41.796158Z"
    }
   },
   "id": "7ba98b74a453a188"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Check if Insulin Carb Ratios are Reasonable\n",
    "\n",
    "The reason for this check is to see if there are any weird values in bolus, basal or carbs. We use the ratio between those values to determine that. \n",
    "\n",
    "We consider that the ratio between bolus and basal should be from 40-60 to 70-30. \n",
    "\n",
    "Reasoning carb ratio: Imagine that 1U of insulin covers around 10-15 g of carbohydrates. If it is 10, there is a bolus-carbs relationship of 1:10. \n",
    "\n",
    "So if we let the gap be from 5 to 50% of \"normal\" ratios, we say that it is normal that one bolus dose covers everything from 5 to 50g of carbohydrates."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "108ce486c016f658"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def style_insulin_carb_ratios(df_features):\n",
    "    # We expect the basal-bolus ratio to be between 30-60% of total insulin, bolus to be around 40-70%\n",
    "    # And bolus should be around 5-50% of carbs\n",
    "    df_features = df_features.applymap(lambda val: highlight_range_severity(val, 30, 60), subset=['daily_basal_ratio'])\n",
    "    df_features = df_features.applymap(lambda val: highlight_range_severity(val, 40, 70), subset=['daily_bolus_ratio'])\n",
    "    df_features = df_features.applymap(lambda val: highlight_range_severity(val, 5, 50), subset=['daily_carbs_ratio'])\n",
    "    return df_features"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-04T21:29:42.112149Z",
     "start_time": "2024-12-04T21:29:42.110521Z"
    }
   },
   "id": "853bf0daaf89e8d6"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-04T21:29:42.267259Z",
     "start_time": "2024-12-04T21:29:42.263244Z"
    }
   },
   "id": "af4581b49ed40f76"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a3ffb4b8ab6f69ec"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save the Color Coded Data "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "86d2a5a4516dbc5f"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def style_all_columns_and_save(df_features, is_test):\n",
    "    df_features = style_feature_sparsity(df_features)\n",
    "    df_features = style_cgm_and_heartrate(df_features)\n",
    "    df_features = style_insulin_carb_ratios(df_features)\n",
    "    \n",
    "    if is_test:\n",
    "        save_file_name = f'{file_name.split(\".\")[0]}_test.xlsx'\n",
    "    else:\n",
    "        save_file_name = f'{file_name.split(\".\")[0]}_train.xlsx'\n",
    "    save_path = os.path.join('..', 'data_diagnostics', save_file_name)\n",
    "    df_features.to_excel(save_path, engine='openpyxl', index=False)\n",
    "\n",
    "style_all_columns_and_save(train_summary_df, is_test=False)\n",
    "style_all_columns_and_save(test_summary_df, is_test=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-04T21:30:14.286434Z",
     "start_time": "2024-12-04T21:30:14.101426Z"
    }
   },
   "id": "140fb8b16c5a617"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: Would be nice to have the files sorted with the \"best\" ids on top / bottom"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-04T21:29:43.185707Z"
    }
   },
   "id": "eaed194c8a23eb10"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-04T21:29:43.186937Z",
     "start_time": "2024-12-04T21:29:43.186872Z"
    }
   },
   "id": "83dacc30b300de5c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-04T21:29:43.188386Z",
     "start_time": "2024-12-04T21:29:43.187603Z"
    }
   },
   "id": "72f8ac5f34c95c53"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-04T21:22:00.599235Z"
    }
   },
   "id": "31c91654084dba6a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-04T21:22:00.599642Z"
    }
   },
   "id": "f78f61bf5916c979"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
